# -*- coding: utf-8 -*-
"""Sign_Language_Alphabets_Detection_and_Recognition_using_YOLOv8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ITdJrATdpu3zE99HYPXZ42exQWLrWRp0

#**Importing the Required Libraries**
"""

import os

import glob

from IPython.display import Image, display

from IPython import display

display.clear_output()

"""# **In the First Step, We need to check whether we have access to the GPU or not**"""

!nvidia-smi

HOME = os.getcwd()

print(HOME)

"""#**Installing Ultralytics using Pip Install**"""

!pip install ultralytics

"""##Checking whether YOLOv8 is Installed and its working Fine"""

import ultralytics

ultralytics.checks()

"""#**Importing the American Sign Language Alphabets Dataset from Roboflow**"""

# Commented out IPython magic to ensure Python compatibility.
!mkdir {HOME}/datasets
# %cd {HOME}/datasets

!pip install roboflow

from roboflow import Roboflow
rf = Roboflow(api_key="70SpXc1OmTXzM9mxngGh")
project = rf.workspace("david-lee-d0rhs").project("american-sign-language-letters")
dataset = project.version(1).download("yolov5")

"""#**Train the YOLOv8 Model on the Custom Dataset**"""

# Commented out IPython magic to ensure Python compatibility.
# %cd {HOME}

# Commented out IPython magic to ensure Python compatibility.
# %cd {dataset.location}

# Commented out IPython magic to ensure Python compatibility.
# %cd {HOME}

!yolo task=detect mode=train model=yolov8l.pt data={dataset.location}/data.yaml epochs=50 imgsz=800

!ls {HOME}/runs/detect/train/

"""#**Displaying the Confusion Matrix**"""

# Commented out IPython magic to ensure Python compatibility.
# %cd {HOME}
Image(filename=f'{HOME}/runs/detect/train/confusion_matrix.png', width=900)

"""#**Training and Validation Loss**"""

# Commented out IPython magic to ensure Python compatibility.
# %cd {HOME}
Image(filename=f'{HOME}/runs/detect/train/results.png', width=600)

# Commented out IPython magic to ensure Python compatibility.
# %cd {HOME}
Image(filename=f'{HOME}/runs/detect/train/val_batch0_pred.jpg', width=600)

"""#**Validate Custom Model**"""

# Commented out IPython magic to ensure Python compatibility.
# %cd {HOME}

!yolo task=detect mode=val model={HOME}/runs/best.pt data={dataset.location}/data.yaml

"""#**Inference with Custom Model**"""

# Commented out IPython magic to ensure Python compatibility.
# %cd {HOME}
!yolo task=detect mode=predict model={HOME}/runs/best.pt conf=0.25 source={dataset.location}/test/images

for image_path in glob.glob(f'{HOME}/runs/detect/predict/*.jpg')[:3]:
      display(Image(filename=image_path, width=600))
      print("\n")

"""#**Testing on a Demo Video**"""

# Commented out IPython magic to ensure Python compatibility.
# %cd {HOME}
!yolo task=detect mode=predict model={HOME}/runs/best.pt conf=0.25 source='/content/demovideo/testvideo1.mp4'

"""#**Display the Demo Video**"""

!rm "/content/result_compressed.mp4"

from IPython.display import HTML
from base64 import b64encode
import os

# Input video path
save_path = '/content/runs/detect/predict2/testvideo1.mp4'

# Compressed video path
compressed_path = "/content/result_compressed.mp4"

os.system(f"ffmpeg -i {save_path} -vcodec libx264 {compressed_path}")

# Show video
mp4 = open(compressed_path,'rb').read()
data_url = "data:video/mp4;base64," + b64encode(mp4).decode()
HTML("""
<video width=400 controls>
      <source src="%s" type="video/mp4">
</video>
""" % data_url)

